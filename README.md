# ğŸ§© Projeto: Arquitetura Hexagonal com Spring Boot, Kafka, MongoDB e WireMock

Este projeto demonstra na prÃ¡tica a **Arquitetura Hexagonal (Ports and Adapters)** utilizando:
- **Java 17**
- **Spring Boot 3**
- **MongoDB**
- **Apache Kafka**
- **Feign Client + WireMock**
- **Docker Compose**
- **Ferramentas de apoio**: Postman, Kafkalytic e Offset Explorer.

---

## ğŸ§  Conceitos Fundamentais

### ğŸ—ï¸ Arquitetura Hexagonal

A Arquitetura Hexagonal, tambÃ©m conhecida como **Ports and Adapters**, tem como objetivo **isolar a lÃ³gica de negÃ³cio** (domÃ­nio) das dependÃªncias externas, como bancos de dados, mensagerias, frameworks ou APIs externas.

Ela organiza o sistema em trÃªs camadas principais:

1. **Core (DomÃ­nio + Casos de Uso)**  
   ContÃ©m as regras de negÃ³cio puras da aplicaÃ§Ã£o.  
   â†’ NÃ£o depende de frameworks ou tecnologias externas.

2. **Ports (Interfaces)**  
   Definem *contratos* de entrada e saÃ­da da aplicaÃ§Ã£o.  
   â†’ â€œPortasâ€ que permitem comunicaÃ§Ã£o entre o domÃ­nio e o mundo externo.

3. **Adapters (ImplementaÃ§Ãµes)**  
   Implementam os *ports*, conectando o domÃ­nio a:
    - Banco de dados (MongoDB)
    - Mensageria (Kafka)
    - APIs externas (Feign Client / WireMock)
    - Controllers REST (Spring MVC)

Essa abordagem garante **baixo acoplamento** e **alta testabilidade**, permitindo substituir tecnologias facilmente (ex.: trocar Mongo por Postgres sem afetar o domÃ­nio).

---

## âš™ï¸ Arquitetura do Projeto

hexagonal
â”œâ”€â”€ adapters
â”‚ â”œâ”€â”€ in
â”‚ â”‚ â”œâ”€â”€ controller # ExposiÃ§Ã£o via REST (API)
â”‚ â”‚ â””â”€â”€ consumer # Consumo de mensagens Kafka
â”‚ â””â”€â”€ out
â”‚ â”œâ”€â”€ repository # Acesso ao MongoDB
â”‚ â”œâ”€â”€ client # ComunicaÃ§Ã£o com serviÃ§o externo (Feign)
â”‚ â””â”€â”€ mapper # MapStruct mappers
â”‚
â”œâ”€â”€ application
â”‚ â”œâ”€â”€ core
â”‚ â”‚ â”œâ”€â”€ domain # Entidades do domÃ­nio
â”‚ â”‚ â””â”€â”€ usecase # Casos de uso (regras de negÃ³cio)
â”‚ â””â”€â”€ ports
â”‚ â”œâ”€â”€ in # Portas de entrada (chamadas externas)
â”‚ â””â”€â”€ out # Portas de saÃ­da (infraestrutura)
â”‚
â”œâ”€â”€ config # Beans de configuraÃ§Ã£o Spring
â””â”€â”€ HexagonalApplication.java # Classe principal

yaml
Copiar cÃ³digo

---

## ğŸš€ ExecuÃ§Ã£o do Projeto

### ğŸ”§ 1. Subir os containers Docker

Na raiz do projeto:


docker compose up -d
Isso iniciarÃ¡:

Zookeeper â†’ porta 2181

Kafka â†’ porta 9092

Kafdrop (UI Kafka) â†’ porta 9000

MongoDB â†’ porta 27017

Mongo Express (UI MongoDB) â†’ porta 8083

Verifique com:

bash
Copiar cÃ³digo
docker ps
ğŸ”Œ 2. Subir o WireMock
O WireMock simula o microserviÃ§o externo de CEP (Address API).

No diretÃ³rio onde estÃ¡ o .jar:

bash
Copiar cÃ³digo
cd C:\Users\edson\Downloads
java -jar wiremock-standalone-4.0.0-beta.15.jar --port 8082
ğŸ“ Endpoint simulado:

bash
Copiar cÃ³digo
http://localhost:8082/addresses/{zipCode}
Exemplo de resposta mockada:

json
Copiar cÃ³digo
{
  "street": "Rua Hexagonal",
  "city": "UberlÃ¢ndia",
  "state": "Minas Gerais"
}
ğŸ§© 3. Executar a aplicaÃ§Ã£o Spring Boot
Na raiz do projeto:

bash
Copiar cÃ³digo
./gradlew bootRun
A aplicaÃ§Ã£o sobe em:

arduino
Copiar cÃ³digo
http://localhost:8081
ğŸ§ª Testes e ValidaÃ§Ãµes
ğŸ§° Postman
â• Criar cliente (POST)
bash
Copiar cÃ³digo
POST http://localhost:8081/api/v1/customers
Body (JSON):

json
Copiar cÃ³digo
{
  "name": "Edson",
  "cpf": "12345678901",
  "zipCode": "38400001"
}
ğŸ” Buscar cliente (GET)
bash
Copiar cÃ³digo
GET http://localhost:8081/api/v1/customers/{id}
âœï¸ Atualizar cliente (PUT)
bash
Copiar cÃ³digo
PUT http://localhost:8081/api/v1/customers/{id}
Body (JSON):

json
Copiar cÃ³digo
{
  "name": "Edson Rego",
  "cpf": "12345678901",
  "zipCode": "38400001"
}
âŒ Deletar cliente (DELETE)
bash
Copiar cÃ³digo
DELETE http://localhost:8081/api/v1/customers/{id}
ğŸ’¬ Kafkalytic (VS Code Plugin)
Utilize para publicar mensagens manualmente no tÃ³pico tp-cpf-validated.

Mensagem de exemplo:

json
Copiar cÃ³digo
{
  "id": "691244db8dff586dc37107e9",
  "name": "Edson Rego",
  "zipCode": "38400001",
  "cp": "12345678901",
  "isValidCpf": true
}
O ReceiveValidatedCpfConsumer consumirÃ¡ esta mensagem e atualizarÃ¡ o cliente no MongoDB com isValidCpf = true.

ğŸ“Š Offset Explorer (antigo Kafka Tool)
Ferramenta desktop para visualizar tÃ³picos Kafka e mensagens publicadas.

Adicione o broker: localhost:9092

Expanda o tÃ³pico tp-cpf-validated

Veja as mensagens publicadas (via API ou Kafkalytic)

Monitore o offset e o consumo

ğŸƒ MongoDB CLI ou Mongo Express
Acessar via terminal:
bash
Copiar cÃ³digo
docker exec -it mongo bash
mongosh -u root -p example
use hexagonal
db.customers.find().pretty()
Ou via interface web:
ğŸ‘‰ http://localhost:8083
Login:

user: root

password: example

ColeÃ§Ã£o: customers

ğŸ”„ Fluxo Completo do Sistema
O cliente Ã© criado via POST /customers.

O serviÃ§o publica o CPF no tÃ³pico tp-cpf-validation (Kafka Producer).

Um microserviÃ§o externo (simulado via WireMock) valida o CPF.

Uma mensagem com isValidCpf=true Ã© publicada no tÃ³pico tp-cpf-validated.

O consumidor (ReceiveValidatedCpfConsumer) lÃª a mensagem e atualiza o registro no MongoDB.

Tudo pode ser acompanhado via:

Mongo Express (dados persistidos)

Kafdrop (mensagens trafegando)

Kafkalytic (publicar manualmente)

Offset Explorer (monitorar offsets)

ğŸ§¾ Stack TÃ©cnica
Componente	FunÃ§Ã£o
Spring Boot 3.4.0	Framework principal
Spring Data MongoDB	PersistÃªncia no MongoDB
Spring Cloud OpenFeign	ComunicaÃ§Ã£o REST com WireMock
Spring Kafka	ProduÃ§Ã£o e consumo de mensagens
WireMock	Mock do microserviÃ§o de endereÃ§o
Docker Compose	OrquestraÃ§Ã£o de serviÃ§os
MapStruct + Lombok	Mapeamento e geraÃ§Ã£o de boilerplate
Kafkalytic / Offset Explorer	VisualizaÃ§Ã£o e publicaÃ§Ã£o de mensagens Kafka

ğŸ§  Autor
Edson Gomes do Rego
System Support Engineer | Java Full Stack Developer
ğŸ’¼ ThoughtWorks | ğŸ“ Eng. da ComputaÃ§Ã£o â€“ Univesp
ğŸ”— LinkedIn | GitHub

ğŸ“š Este projeto Ã© baseado no curso â€œArquitetura Hexagonal com Java e Spring Bootâ€ do professor Danilo Arantes.

```bash
